# data_path: /home/dkrivenkov/program/autofocusing/data/data_domain_1/dualLED_3domains/train_dualLED_3domains
# same_data_path: /home/dkrivenkov/program/autofocusing/data/data_domain_1/dualLED_3domains/testRawData_dualLED_sameProtocol
# diff_data_path: /home/dkrivenkov/program/autofocusing/data/data_domain_1/dualLED_3domains/testRawData_dualLED_diffProtocol


data_path: /home/dkrivenkov/program/autofocusing/data/data_channel/incoherent_RGBchannels/train_incoherent_RGBChannels
same_data_path: /home/dkrivenkov/program/autofocusing/data/data_channel/incoherent_RGBchannels/testRawData_incoherent_sameProtocol
diff_data_path: /home/dkrivenkov/program/autofocusing/data/data_channel/incoherent_RGBchannels/testRawData_incoherent_diffProtocol

train_ratio: 0.8
smart_split: false

train_dataset: 
  _target_: dataset.focusdataset.FocusingDataset
  pattern: Seg(\d+)_defocus(\-?\d+)
  images_data: ???

val_dataset: 
  _target_: dataset.focusdataset.FocusingDataset
  pattern: Seg(\d+)_defocus(\-?\d+)
  images_data: ???

test_dataset: 
  _target_: dataset.focusdataset.FocusingDataset
  pattern: defocus(\-?\d+)
  images_data: ???

train_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 8
  drop_last: true
  num_workers: 10

val_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 8
  num_workers: 10

test_dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 8
  num_workers: 10


train_transform:
  _target_: dataset.transform.TrainFocusingTransform
  mean: 
    - 0.485
    - 0.456
    - 0.406
  std:
    - 0.229
    - 0.224
    - 0.225
  add_fourier: false

val_transform:
  _target_: dataset.transform.ValFocusingTransform
  mean: 
    - 0.485
    - 0.456
    - 0.406
  std:
    - 0.229
    - 0.224
    - 0.225
  add_fourier: false

test_transform:
  _target_: dataset.transform.TestFocusingTransform
  mean: 
    - 0.485
    - 0.456
    - 0.406
  std:
    - 0.229
    - 0.224
    - 0.225
  add_fourier: false
  crop_size:
    - 1120
    - 1120
